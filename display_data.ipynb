{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import medmnist\n",
    "from medmnist import INFO\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "from models.FunctorModel import FunctorModel\n",
    "from utils.initialise_W_utils import initialise_W_real_Cn_irreps\n",
    "from utils.char_tables import Z2_CharTable, CharTable, Cn_CharTable\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(path):\n",
    "    result = {}\n",
    "    event_acc = EventAccumulator(path)\n",
    "    event_acc.Reload()\n",
    "    #print(event_acc.Tags()['scalars'])\n",
    "    x = event_acc.Scalars('test_acc/dataloader_idx_0')\n",
    "    assert len(x) == 1\n",
    "    result['acc'] = x[0].value\n",
    "    x = event_acc.Scalars('aug_test_acc/dataloader_idx_1')\n",
    "    assert len(x) == 1\n",
    "    result['aug_acc'] = x[0].value\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_W_from_checkpoint(path):\n",
    "    checkpoint = torch.load(path, map_location='cuda:0')\n",
    "    base_model = checkpoint['hyper_parameters']['model_flag']\n",
    "    n_classes = checkpoint['hyper_parameters']['n_classes']\n",
    "    task = checkpoint['hyper_parameters']['task']\n",
    "    data_flag = checkpoint['hyper_parameters']['data_flag']\n",
    "    size = checkpoint['hyper_parameters']['size']\n",
    "    name = checkpoint['hyper_parameters']['run']\n",
    "    W_init = checkpoint['hyper_parameters']['W_init']\n",
    "    lambda_t = checkpoint['hyper_parameters']['lambda_t']\n",
    "    lambda_W = checkpoint['hyper_parameters']['lambda_W']\n",
    "    W_block_size = checkpoint['hyper_parameters']['W_block_size']\n",
    "    fix_rep = checkpoint['hyper_parameters']['fix_rep']\n",
    "    mod_exponent = checkpoint['hyper_parameters']['modularity_exponent']\n",
    "    model = FunctorModel(base_model, 3, n_classes, task, data_flag, size, name, W_init=W_init, lambda_t=lambda_t, lambda_W=lambda_W, W_block_size=W_block_size, fix_rep=fix_rep, modularity_exponent=mod_exponent)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.eval()\n",
    "    model.to('cuda:0')\n",
    "    return model.get_W(), W_init, fix_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(s, lambda_t):\n",
    "    if \"vanilla\" in s:\n",
    "        return \"Vanilla\"\n",
    "    if \"D8_regular_functor\" in s:\n",
    "        return f\"regular_{lambda_t}\"\n",
    "    if \"only\" in s:\n",
    "        return f\"fineTunedAfterEquiv\"\n",
    "    if \"fine_tune\" in s and \"only\" not in s:\n",
    "        return f\"fineTunedWithoutEquiv\"\n",
    "    return \"regular\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_1.0_lambdaW_0.1/version_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 02:46:49.068013: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-06 02:46:49.082601: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746496009.100795 3473152 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746496009.106109 3473152 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-06 02:46:49.127008: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/tmp/ipykernel_3473152/1239762647.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data = pd.concat([data, pd.DataFrame([results])])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_1.0_lambdaW_0.1/version_1\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_1.0_lambdaW_0.1/version_2\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_1.0_lambdaW_0.1/version_3\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_1.0_lambdaW_0.1/version_4\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_0.0_lambdaW_0.1/version_0\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_0.0_lambdaW_0.1/version_1\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_0.0_lambdaW_0.1/version_2\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_0.0_lambdaW_0.1/version_3\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_0.0_lambdaW_0.1/version_4\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_0.05_lambdaW_0.1/version_0\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_0.05_lambdaW_0.1/version_1\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_0.05_lambdaW_0.1/version_2\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_0.05_lambdaW_0.1/version_3\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_0.05_lambdaW_0.1/version_4\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_1.0_lambdaW_0.1/version_0\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_1.0_lambdaW_0.1/version_1\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_1.0_lambdaW_0.1/version_2\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_1.0_lambdaW_0.1/version_3\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_1.0_lambdaW_0.1/version_4\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_0.5_lambdaW_0.1/version_0\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_0.5_lambdaW_0.1/version_1\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_0.5_lambdaW_0.1/version_2\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_0.5_lambdaW_0.1/version_3\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_0.5_lambdaW_0.1/version_4\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_0.05_lambdaW_0.1/version_0\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_0.05_lambdaW_0.1/version_1\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_0.05_lambdaW_0.1/version_2\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_0.05_lambdaW_0.1/version_3\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_0.05_lambdaW_0.1/version_4\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_2.0_lambdaW_0.1/version_0\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_2.0_lambdaW_0.1/version_1\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_2.0_lambdaW_0.1/version_2\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_2.0_lambdaW_0.1/version_3\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_2.0_lambdaW_0.1/version_4\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_0.5_lambdaW_0.1/version_0\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_0.5_lambdaW_0.1/version_1\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_0.5_lambdaW_0.1/version_2\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_0.5_lambdaW_0.1/version_3\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_0.5_lambdaW_0.1/version_4\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_2.0_lambdaW_0.1/version_0\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_2.0_lambdaW_0.1/version_1\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_2.0_lambdaW_0.1/version_2\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_2.0_lambdaW_0.1/version_3\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_2.0_lambdaW_0.1/version_4\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_0.5_lambdaW_0.1/version_0\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_0.5_lambdaW_0.1/version_1\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_0.5_lambdaW_0.1/version_2\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_0.5_lambdaW_0.1/version_3\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_0.5_lambdaW_0.1/version_4\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_2.0_lambdaW_0.1/version_0\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_2.0_lambdaW_0.1/version_1\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_2.0_lambdaW_0.1/version_2\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_2.0_lambdaW_0.1/version_3\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_2.0_lambdaW_0.1/version_4\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_0.0_lambdaW_0.1/version_0\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_0.0_lambdaW_0.1/version_1\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_0.0_lambdaW_0.1/version_2\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_0.0_lambdaW_0.1/version_3\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.008_resnet18_lambdaT_0.0_lambdaW_0.1/version_4\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_1.0_lambdaW_0.1/version_0\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_1.0_lambdaW_0.1/version_1\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_1.0_lambdaW_0.1/version_2\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_1.0_lambdaW_0.1/version_3\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.0009_resnet18_lambdaT_1.0_lambdaW_0.1/version_4\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_0.0_lambdaW_0.1/version_0\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_0.0_lambdaW_0.1/version_1\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_0.0_lambdaW_0.1/version_2\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_0.0_lambdaW_0.1/version_3\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_0.0_lambdaW_0.1/version_4\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_0.05_lambdaW_0.1/version_0\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_0.05_lambdaW_0.1/version_1\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_0.05_lambdaW_0.1/version_2\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_0.05_lambdaW_0.1/version_3\n",
      "./tb_logs/pathmnist/ddmnist_c4/id_89_lr=0.005_resnet18_lambdaT_0.05_lambdaW_0.1/version_4\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(columns=[\"dataset\", \"lambdaT\", \"lambdaW\", \"W_init\", \"fixed_rep\", \"algebra_satisfied\", \"acc\", \"auc\"])\n",
    "\n",
    "\n",
    "datasets = list(INFO.keys())\n",
    "#datasets = [dataset for dataset in datasets if \"3d\" not in dataset]\n",
    "datasets = ['pathmnist']\n",
    "tb_logs = \"./tb_logs\"\n",
    "\n",
    "# Select dataset\n",
    "for dataset in datasets:\n",
    "    path = f\"{tb_logs}/{dataset}/ddmnist_c4\"\n",
    "    experiment_paths = os.listdir(path)\n",
    "\n",
    "    #Select experiment\n",
    "    for experiment in experiment_paths:\n",
    "        lambda_t = experiment.split(\"lambdaT_\")[1].split(\"_\")[0]\n",
    "        lambda_W = experiment.split(\"lambdaW_\")[1].split(\"_\")[0]\n",
    "        #lr = 0.0005#experiment.split(\"lr=\")[1].split(\"_\")[0]\n",
    "        if \"lr=\" in experiment:\n",
    "            lr = experiment.split(\"lr=\")[1].split(\"_\")[0]\n",
    "        else:\n",
    "            lr = 0.0005\n",
    "\n",
    "        #Select version\n",
    "        for version in range(0, 5):\n",
    "            result_path = f\"{path}/{experiment}/version_{version}\"\n",
    "            print(result_path)\n",
    "            results = get_results(result_path)\n",
    "            results['lambdaT'] = lambda_t\n",
    "            results['lambdaW'] = lambda_W\n",
    "            results['dataset'] = dataset\n",
    "\n",
    "            if 'vanilla' in experiment:\n",
    "                W_init = 'Vanilla'\n",
    "                fixed_rep = 'None'\n",
    "                n_ones = 'None'\n",
    "                n_neg_ones = 'None'\n",
    "                algebra_satisfied = 'None'\n",
    "\n",
    "            else:\n",
    "                #W, W_init, fixed_rep = get_W_from_checkpoint(f\"{result_path}/checkpoints/best_model.ckpt\")\n",
    "                if 'MSE' in experiment:\n",
    "                    W_init += 'MSE'\n",
    "                # eigs, _ = torch.linalg.eig(W)\n",
    "                \n",
    "                # n_ones = torch.sum(torch.abs(eigs - 1) < 1e-2).item()\n",
    "                # n_neg_ones = torch.sum(torch.abs(eigs + 1) < 1e-2).item()\n",
    "\n",
    "                # algebra_loss = torch.dist(W @ W, torch.eye(W.shape[0], device=W.device)).item()\n",
    "                # if algebra_loss < 1e-2:\n",
    "                #     algebra_satisfied = True\n",
    "                # else:\n",
    "                #     algebra_satisfied = False\n",
    "                W_init = 'regular'\n",
    "                n_ones = 256\n",
    "                n_neg_ones = 256\n",
    "                algebra_satisfied = True\n",
    "                fixed_rep = True\n",
    "\n",
    "            #results['W_init'] = f\"{W_init}_{lambda_t}\" \n",
    "            #W_init = \"fine_tuned\" if lambda_t == '0.0' and W_init != 'Vanilla' else W_init\n",
    "            results['W_init'] = get_name(experiment, lambda_t)\n",
    "            results['fixed_rep'] = fixed_rep\n",
    "            results['n_ones'] = n_ones\n",
    "            results['n_neg_ones'] = n_neg_ones\n",
    "            results['algebra_satisfied'] = algebra_satisfied\n",
    "            results['lr'] = lr\n",
    "            if \"id_\" in experiment:\n",
    "                layer_id = experiment.split(\"id_\")[1].split(\"_\")[0]\n",
    "            else:\n",
    "                layer_id = '9'\n",
    "\n",
    "            results['layer_id'] = layer_id\n",
    "\n",
    "            data = pd.concat([data, pd.DataFrame([results])])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambdaT</th>\n",
       "      <th>layer_id</th>\n",
       "      <th>lr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">89</th>\n",
       "      <th>0.0009</th>\n",
       "      <td>0.87652</td>\n",
       "      <td>0.002201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005</th>\n",
       "      <td>0.89092</td>\n",
       "      <td>0.005358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.008</th>\n",
       "      <td>0.88060</td>\n",
       "      <td>0.010118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.05</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">89</th>\n",
       "      <th>0.0009</th>\n",
       "      <td>0.89884</td>\n",
       "      <td>0.002423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005</th>\n",
       "      <td>0.88944</td>\n",
       "      <td>0.004212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.008</th>\n",
       "      <td>0.90192</td>\n",
       "      <td>0.002577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0.5</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">89</th>\n",
       "      <th>0.0009</th>\n",
       "      <td>0.90396</td>\n",
       "      <td>0.003830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005</th>\n",
       "      <td>0.89736</td>\n",
       "      <td>0.004823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.008</th>\n",
       "      <td>0.89492</td>\n",
       "      <td>0.004833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1.0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">89</th>\n",
       "      <th>0.0009</th>\n",
       "      <td>0.91076</td>\n",
       "      <td>0.003096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005</th>\n",
       "      <td>0.90460</td>\n",
       "      <td>0.002889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.008</th>\n",
       "      <td>0.89524</td>\n",
       "      <td>0.007937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2.0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">89</th>\n",
       "      <th>0.0009</th>\n",
       "      <td>0.89128</td>\n",
       "      <td>0.004166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.005</th>\n",
       "      <td>0.90520</td>\n",
       "      <td>0.004099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.008</th>\n",
       "      <td>0.89688</td>\n",
       "      <td>0.001248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            mean       sem\n",
       "lambdaT layer_id lr                       \n",
       "0.0     89       0.0009  0.87652  0.002201\n",
       "                 0.005   0.89092  0.005358\n",
       "                 0.008   0.88060  0.010118\n",
       "0.05    89       0.0009  0.89884  0.002423\n",
       "                 0.005   0.88944  0.004212\n",
       "                 0.008   0.90192  0.002577\n",
       "0.5     89       0.0009  0.90396  0.003830\n",
       "                 0.005   0.89736  0.004823\n",
       "                 0.008   0.89492  0.004833\n",
       "1.0     89       0.0009  0.91076  0.003096\n",
       "                 0.005   0.90460  0.002889\n",
       "                 0.008   0.89524  0.007937\n",
       "2.0     89       0.0009  0.89128  0.004166\n",
       "                 0.005   0.90520  0.004099\n",
       "                 0.008   0.89688  0.001248"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show test_acc grouped by lambdaT\n",
    "summary = data.groupby(['lambdaT', 'layer_id', 'lr'])['aug_acc'].agg(['mean', 'sem'])\n",
    "summary.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>lambdaT</th>\n",
       "      <th>lambdaW</th>\n",
       "      <th>W_init</th>\n",
       "      <th>fixed_rep</th>\n",
       "      <th>algebra_satisfied</th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>n_ones</th>\n",
       "      <th>n_neg_ones</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pathmnist</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>regular</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pathmnist</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>regular</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pathmnist</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>regular</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pathmnist</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>regular</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pathmnist</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>regular</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset lambdaT lambdaW   W_init fixed_rep algebra_satisfied     acc  \\\n",
       "0  pathmnist     1.5     0.1  regular      True              True  0.9116   \n",
       "0  pathmnist     1.5     0.1  regular      True              True  0.9022   \n",
       "0  pathmnist     1.5     0.1  regular      True              True  0.9096   \n",
       "0  pathmnist     1.5     0.1  regular      True              True  0.9178   \n",
       "0  pathmnist     1.5     0.1  regular      True              True  0.9154   \n",
       "\n",
       "   auc  n_ones  n_neg_ones  \n",
       "0  NaN   256.0       256.0  \n",
       "0  NaN   256.0       256.0  \n",
       "0  NaN   256.0       256.0  \n",
       "0  NaN   256.0       256.0  \n",
       "0  NaN   256.0       256.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"all_d8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flip_1.0' 'regular_1.0' 'Vanilla']\n"
     ]
    }
   ],
   "source": [
    "other_data = pd.read_csv(\"results/z2/results_regular_sweep.csv\")\n",
    "data = pd.read_csv(\"results_flip.csv\")\n",
    "\n",
    "vanilla_data = pd.read_csv(\"results/z2/results_big_run.csv\")\n",
    "vanilla_data = vanilla_data[vanilla_data['W_init'].isin(['Vanilla'])]\n",
    "\n",
    "# Merge other_data and data\n",
    "merged_data = pd.concat([data, other_data, vanilla_data], ignore_index=True)\n",
    "# Delete entries where W_init='orthogonal', 'orthogonalMSE', 'block_diagonal', 'identity'\n",
    "merged_data = merged_data[merged_data['W_init'].isin(['regular_1.0', 'Vanilla', 'flip_1.0'])]\n",
    "\n",
    "print(merged_data['W_init'].unique())\n",
    "\n",
    "# Rename regular to regular_0.5\n",
    "data = merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>W_init</th>\n",
       "      <th>mean</th>\n",
       "      <th>sem</th>\n",
       "      <th>significant_error_bars</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bloodmnist</td>\n",
       "      <td>Vanilla</td>\n",
       "      <td>0.970564</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bloodmnist</td>\n",
       "      <td>fineTunedAfterEquiv</td>\n",
       "      <td>0.968781</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.001783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bloodmnist</td>\n",
       "      <td>fineTunedWithoutEquiv</td>\n",
       "      <td>0.972581</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bloodmnist</td>\n",
       "      <td>regular_1.0</td>\n",
       "      <td>0.973136</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bloodmnist</td>\n",
       "      <td>regular_2.0</td>\n",
       "      <td>0.971266</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>breastmnist</td>\n",
       "      <td>Vanilla</td>\n",
       "      <td>0.819231</td>\n",
       "      <td>0.015432</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>breastmnist</td>\n",
       "      <td>fineTunedAfterEquiv</td>\n",
       "      <td>0.835897</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>False</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>breastmnist</td>\n",
       "      <td>fineTunedWithoutEquiv</td>\n",
       "      <td>0.828846</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>False</td>\n",
       "      <td>0.009615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>breastmnist</td>\n",
       "      <td>regular_1.0</td>\n",
       "      <td>0.811538</td>\n",
       "      <td>0.010692</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.007692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>breastmnist</td>\n",
       "      <td>regular_2.0</td>\n",
       "      <td>0.797436</td>\n",
       "      <td>0.016307</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.021795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dataset                 W_init      mean       sem  \\\n",
       "0   bloodmnist                Vanilla  0.970564  0.001327   \n",
       "1   bloodmnist    fineTunedAfterEquiv  0.968781  0.001678   \n",
       "2   bloodmnist  fineTunedWithoutEquiv  0.972581  0.001665   \n",
       "3   bloodmnist            regular_1.0  0.973136  0.000533   \n",
       "4   bloodmnist            regular_2.0  0.971266  0.001278   \n",
       "5  breastmnist                Vanilla  0.819231  0.015432   \n",
       "6  breastmnist    fineTunedAfterEquiv  0.835897  0.004984   \n",
       "7  breastmnist  fineTunedWithoutEquiv  0.828846  0.007466   \n",
       "8  breastmnist            regular_1.0  0.811538  0.010692   \n",
       "9  breastmnist            regular_2.0  0.797436  0.016307   \n",
       "\n",
       "   significant_error_bars  difference  \n",
       "0                   False    0.000000  \n",
       "1                   False   -0.001783  \n",
       "2                   False    0.002017  \n",
       "3                    True    0.002572  \n",
       "4                   False    0.000702  \n",
       "5                   False    0.000000  \n",
       "6                   False    0.016667  \n",
       "7                   False    0.009615  \n",
       "8                   False   -0.007692  \n",
       "9                   False   -0.021795  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_significance_t_test(mean1, std1, n1, mean2, std2, n2, alpha=0.05):\n",
    "    # Compute the t-statistic and p-value\n",
    "    t_stat, p_value = stats.ttest_ind_from_stats(mean1, std1, n1, mean2, std2, n2, equal_var=False)\n",
    "    if p_value < alpha:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def better_than_baseline(performance, baseline):\n",
    "    if performance > baseline:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def check_significance_error_bars(mean1, sem1, mean2, sem2):\n",
    "    # Compute Standard Error of the Mean (SEM)\n",
    "    # sem1 = std1 / (n1 ** 0.5)\n",
    "    # sem2 = std2 / (n2 ** 0.5)\n",
    "\n",
    "    # Compute error bar ranges\n",
    "    lower1, upper1 = mean1 - sem1, mean1 + sem1\n",
    "    lower2, upper2 = mean2 - sem2, mean2 + sem2\n",
    "    # Check if error bars overlap\n",
    "    if upper1 < lower2 or upper2 < lower1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "STATISTIC = 'acc'\n",
    "POOLING = 'mean'\n",
    "summary = data.groupby(['dataset', 'W_init'])[STATISTIC].agg([POOLING, 'sem'])\n",
    "\n",
    "# Get statistics for W_init = None\n",
    "summary = summary.reset_index()\n",
    "baseline = summary[summary['W_init'] == 'Vanilla']\n",
    "\n",
    "#Apply check significance to each row of summary\n",
    "if POOLING == 'max':\n",
    "    summary['significant_error_bars'] = summary.apply(lambda row: better_than_baseline(row[POOLING],  baseline[POOLING][baseline['dataset']==row['dataset']].values[0]), axis=1)\n",
    "else:\n",
    "    summary['significant_error_bars'] = summary.apply(lambda row: check_significance_error_bars(row[POOLING], row['sem'], \n",
    "                                                                        baseline[POOLING][baseline['dataset']==row['dataset']].values[0], \n",
    "                                                                        baseline['sem'][baseline['dataset']==row['dataset']].values[0]), axis=1)\n",
    "\n",
    "\n",
    "summary['difference'] = summary.apply(lambda row: (row[POOLING] - baseline[POOLING][baseline['dataset']==row['dataset']]).values[0], axis=1)\n",
    "\n",
    "# See when significant error_bars is different than significant t-test\n",
    "#summary[summary['significant_error_bars'] != summary['significant_t_test']].head(100)\n",
    "#summary[(summary['significant_error_bars'] == True) & (summary['difference']>0)].head(100)\n",
    "\n",
    "summary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv(f\"all_d8_summary_{STATISTIC}_{POOLING}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "acc\n"
     ]
    }
   ],
   "source": [
    "print(POOLING)\n",
    "print(STATISTIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h]\n",
      "    \\centering\n",
      "    \\renewcommand{\\arraystretch}{1.2}  % Adjust row height for readability\n",
      "    \\resizebox{\\textwidth}{!}{  % Resize table to fit within the page width\n",
      "        \\begin{tabular}{l|ccccc}\n",
      "            \\hline\n",
      "            Dataset & Vanilla & fineTunedAfterEquiv & fineTunedWithoutEquiv & regular_1.0 & regular_2.0 \\\\ \\hline\n",
      "            bloodmnist & 97.06$\\pm$0.13 & 96.88$\\pm$0.17 & 97.26$\\pm$0.17 & \\textbf{\\textcolor{ForestGreen}{97.31$\\pm$0.05*}} & 97.13$\\pm$0.13 \\\\ \\hline\n",
      "            breastmnist & 81.92$\\pm$1.54 & \\textbf{83.59$\\pm$0.50} & 82.88$\\pm$0.75 & 81.15$\\pm$1.07 & 79.74$\\pm$1.63 \\\\ \\hline\n",
      "            chestmnist & 94.75$\\pm$0.01 & \\textbf{\\textcolor{ForestGreen}{94.76$\\pm$0.01*}} & 94.75$\\pm$0.01 & 94.74$\\pm$0.01 & 94.76$\\pm$0.01 \\\\ \\hline\n",
      "            dermamnist & 76.66$\\pm$0.24 & 76.54$\\pm$0.18 & \\textbf{76.92$\\pm$0.26} & 76.80$\\pm$0.24 & 76.57$\\pm$0.34 \\\\ \\hline\n",
      "            octmnist & 77.26$\\pm$0.42 & 76.42$\\pm$0.48 & 77.07$\\pm$0.38 & \\textbf{77.28$\\pm$0.38} & 77.21$\\pm$0.46 \\\\ \\hline\n",
      "            organamnist & 76.49$\\pm$0.56 & 77.15$\\pm$0.26 & \\textbf{\\textcolor{ForestGreen}{78.09$\\pm$0.57*}} & 77.34$\\pm$0.32 & 76.84$\\pm$0.66 \\\\ \\hline\n",
      "            organcmnist & 75.71$\\pm$0.63 & 76.36$\\pm$0.31 & \\textbf{\\textcolor{ForestGreen}{77.84$\\pm$0.23*}} & 77.11$\\pm$0.85 & \\textcolor{ForestGreen}{77.08$\\pm$0.35*} \\\\ \\hline\n",
      "            organsmnist & 75.49$\\pm$0.24 & 75.52$\\pm$0.35 & \\textbf{\\textcolor{ForestGreen}{76.81$\\pm$0.19*}} & \\textcolor{ForestGreen}{76.12$\\pm$0.20*} & 75.95$\\pm$0.32 \\\\ \\hline\n",
      "            pathmnist & 88.18$\\pm$0.62 & 87.68$\\pm$0.70 & \\textbf{88.66$\\pm$0.61} & 86.89$\\pm$1.08 & 87.94$\\pm$0.82 \\\\ \\hline\n",
      "            pneumoniamnist & 85.66$\\pm$0.81 & 86.63$\\pm$1.12 & 86.70$\\pm$1.42 & 86.73$\\pm$0.71 & \\textbf{86.81$\\pm$1.10} \\\\ \\hline\n",
      "            retinamnist & 51.30$\\pm$0.49 & 51.75$\\pm$0.30 & \\textbf{52.07$\\pm$0.59} & 51.05$\\pm$0.82 & 51.42$\\pm$0.59 \\\\ \\hline\n",
      "            tissuemnist & \\textbf{73.08$\\pm$0.10} & \\textcolor{red}{72.85$\\pm$0.07*} & 72.99$\\pm$0.07 & 72.92$\\pm$0.10 & 73.02$\\pm$0.07 \\\\ \\hline\n",
      "            \\textbf{Aggregate} & 79.46$\\pm$0.65 & 79.68$\\pm$0.49 & \\textbf{80.17$\\pm$0.60} & 79.62$\\pm$0.64 & 79.54$\\pm$0.73 \\\\ \\hline\n",
      "        \\end{tabular}\n",
      "    }\n",
      "    \\caption{Summary of ML experiments. Statistically significant improvements are in \\textcolor{ForestGreen}{green} if positive and \\textcolor{red}{red} if negative. The highest mean in each row is \\textbf{bold}. A * indicates statistical significance. The last row shows the aggregate mean and standard deviation of the means per model.}\n",
      "    \\label{tab:results}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file (adjust the filename if necessary)\n",
    "df = pd.read_csv(f'all_d8_summary_{STATISTIC}_{POOLING}.csv')\n",
    "\n",
    "# Get sorted unique datasets and models.\n",
    "datasets = sorted(df['dataset'].unique())\n",
    "models = sorted(df['W_init'].unique(), key=str)  # Sort by string representation\n",
    "\n",
    "# Create a dictionary for easy lookup: \n",
    "# key = (dataset, W_init) and value = corresponding row as a Series.\n",
    "data_dict = {(row['dataset'], row['W_init']): row for _, row in df.iterrows()}\n",
    "\n",
    "# Start building the LaTeX table\n",
    "latex_lines = [\n",
    "    \"\\\\begin{table}[h]\",\n",
    "    \"    \\\\centering\",\n",
    "    \"    \\\\renewcommand{\\\\arraystretch}{1.2}  % Adjust row height for readability\",\n",
    "    \"    \\\\resizebox{\\\\textwidth}{!}{  % Resize table to fit within the page width\",\n",
    "    \"        \\\\begin{tabular}{l|\" + \"c\" * len(models) + \"}\",\n",
    "    \"            \\\\hline\",\n",
    "    \"            Dataset & \" + \" & \".join(map(str, models)) + \" \\\\\\\\ \\\\hline\"\n",
    "]\n",
    "\n",
    "# Process each dataset row by row\n",
    "for dataset in datasets:\n",
    "    # Extract all entries for the current dataset.\n",
    "    subset = df[df['dataset'] == dataset].copy()\n",
    "    \n",
    "    # Determine the highest mean in this dataset\n",
    "    max_mean = subset[POOLING].max()\n",
    "\n",
    "    # Build the table row for the current dataset\n",
    "    row_entries = []\n",
    "    for model in models:\n",
    "        key = (dataset, model)\n",
    "        if key in data_dict:\n",
    "            row_data = data_dict[key]\n",
    "            # Convert to percentages\n",
    "            mean_val = row_data[POOLING] * 100\n",
    "            std_val = row_data['sem'] * 100\n",
    "            # Append a star if the result is significant.\n",
    "            star = \"*\" if row_data['significant_error_bars'] else \"\"\n",
    "            if POOLING == 'max':\n",
    "                entry = f\"{mean_val:.2f}\"\n",
    "            else:\n",
    "                entry = f\"{mean_val:.2f}$\\\\pm${std_val:.2f}{star}\"\n",
    "            \n",
    "            # Apply coloring if applicable.\n",
    "            if row_data['significant_error_bars']:\n",
    "                if row_data['difference'] > 0:\n",
    "                    entry = f\"\\\\textcolor{{ForestGreen}}{{{entry}}}\"\n",
    "                elif row_data['difference'] < 0:\n",
    "                    entry = f\"\\\\textcolor{{red}}{{{entry}}}\"\n",
    "\n",
    "            # Bold the highest mean value\n",
    "            if row_data[POOLING] == max_mean:\n",
    "                entry = f\"\\\\textbf{{{entry}}}\"\n",
    "        else:\n",
    "            entry = \"-\"\n",
    "        row_entries.append(entry)\n",
    "    \n",
    "    line = f\"            {dataset} & \" + \" & \".join(row_entries) + \" \\\\\\\\ \\\\hline\"\n",
    "    latex_lines.append(line)\n",
    "\n",
    "# Compute aggregate mean and standard deviation of the means per model\n",
    "aggregate_means = df.groupby('W_init')[POOLING].mean() * 100  # Convert to percentages\n",
    "#df['variance'] = df['std'] ** 2\n",
    "# def calculate_pooled_std(x):\n",
    "#     return (((x ** 2).sum() / (len(x) - 1)) ** 0.5)*100\n",
    "# aggregate_stds = df.groupby('W_init')['std'].agg(calculate_pooled_std)\n",
    "def calculate_pooled_sem(x):\n",
    "    return (((x ** 2).sum() / (len(x) - 1)) ** 0.5)*100\n",
    "aggregate_stds = df.groupby('W_init')['sem'].agg(calculate_pooled_sem)\n",
    "\n",
    "# Determine the highest aggregate mean\n",
    "max_aggregate_mean = aggregate_means.max()\n",
    "\n",
    "# Build the final row for aggregate statistics\n",
    "aggregate_row = []\n",
    "for model in models:\n",
    "    mean_val = aggregate_means.get(model, float('nan'))\n",
    "    std_val = aggregate_stds.get(model, float('nan'))\n",
    "    baseline_mean = aggregate_means.get('Vanilla', float('nan'))\n",
    "    baseline_std = aggregate_stds.get('Vanilla', float('nan'))\n",
    "    if POOLING == 'max':\n",
    "        star = \"*\" if better_than_baseline(mean_val, baseline_mean) else \"\"\n",
    "        entry = f\"{mean_val:.2f}\"\n",
    "    else:\n",
    "        star = \"*\" if check_significance_error_bars(mean_val, std_val, baseline_mean, baseline_std) else \"\"\n",
    "        entry = f\"{mean_val:.2f}$\\\\pm${std_val:.2f}{star}\"\n",
    "\n",
    "    # Apply coloring if applicable.\n",
    "    if star == '*':\n",
    "        if mean_val - baseline_mean > 0:\n",
    "            entry = f\"\\\\textcolor{{ForestGreen}}{{{entry}}}\"\n",
    "        elif mean_val - baseline_mean < 0:\n",
    "            entry = f\"\\\\textcolor{{red}}{{{entry}}}\"\n",
    "\n",
    "    # Bold the highest mean\n",
    "    if mean_val == max_aggregate_mean:\n",
    "        entry = f\"\\\\textbf{{{entry}}}\"\n",
    "\n",
    "    aggregate_row.append(entry)\n",
    "\n",
    "# Append aggregate row to the table\n",
    "latex_lines.append(f\"            \\\\textbf{{Aggregate}} & \" + \" & \".join(aggregate_row) + \" \\\\\\\\ \\\\hline\")\n",
    "\n",
    "# Closing the LaTeX table\n",
    "latex_lines.extend([\n",
    "    \"        \\\\end{tabular}\",\n",
    "    \"    }\",\n",
    "    \"    \\\\caption{Summary of ML experiments. Statistically significant improvements are in \\\\textcolor{ForestGreen}{green} if positive and \\\\textcolor{red}{red} if negative. The highest mean in each row is \\\\textbf{bold}. A * indicates statistical significance. The last row shows the aggregate mean and standard deviation of the means per model.}\",\n",
    "    \"    \\\\label{tab:results}\",\n",
    "    \"\\\\end{table}\"\n",
    "])\n",
    "\n",
    "# Combine all lines into one LaTeX table string\n",
    "latex_table = \"\\n\".join(latex_lines)\n",
    "\n",
    "# Print or save the output\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
