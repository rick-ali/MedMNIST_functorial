{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as  TF\n",
    "import medmnist\n",
    "from medmnist import INFO\n",
    "import pytorch_lightning as pl\n",
    "import PIL\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from datasets.CnMedMNIST2D_dataset import CnMedMNISTDataModule\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using x2 angle = 90\n",
      "torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "data_module = CnMedMNISTDataModule('tissuemnist', batch_size=32, resize=False, as_rgb=True, size=28, download=True, x2_angle=90)\n",
    "data_module.setup()\n",
    "train_loader = data_module.train_dataloader()\n",
    "val_loader = data_module.val_dataloader()\n",
    "test_loader = data_module.test_dataloader()\n",
    "\n",
    "\n",
    "for i, ((x1, y1), (x2, y2), transformation_type, covariate) in enumerate(train_loader):\n",
    "    break\n",
    "\n",
    "#imshow(torchvision.utils.make_grid(x1))\n",
    "#imshow(torchvision.utils.make_grid(x2))\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pathmnist',\n",
       " 'chestmnist',\n",
       " 'dermamnist',\n",
       " 'octmnist',\n",
       " 'pneumoniamnist',\n",
       " 'retinamnist',\n",
       " 'breastmnist',\n",
       " 'bloodmnist',\n",
       " 'tissuemnist',\n",
       " 'organamnist',\n",
       " 'organcmnist',\n",
       " 'organsmnist',\n",
       " 'organmnist3d',\n",
       " 'nodulemnist3d',\n",
       " 'adrenalmnist3d',\n",
       " 'fracturemnist3d',\n",
       " 'vesselmnist3d',\n",
       " 'synapsemnist3d']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from medmnist import INFO\n",
    "\n",
    "datasets = list(INFO.keys())\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'orgnamnist3d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMedMNIST2D_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MedMNISTDataModule\n\u001b[0;32m----> 2\u001b[0m data_module \u001b[38;5;241m=\u001b[39m \u001b[43mMedMNISTDataModule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43morgnamnist3d\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_rgb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m data_module\u001b[38;5;241m.\u001b[39msetup()\n\u001b[1;32m      4\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m data_module\u001b[38;5;241m.\u001b[39mtrain_dataloader()\n",
      "File \u001b[0;32m~/git-repos/MedMNIST_functorial/datasets/MedMNIST2D_dataset.py:19\u001b[0m, in \u001b[0;36mMedMNISTDataModule.__init__\u001b[0;34m(self, data_flag, batch_size, resize, as_rgb, size, download)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload \u001b[38;5;241m=\u001b[39m download\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo \u001b[38;5;241m=\u001b[39m \u001b[43mINFO\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata_flag\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDataClass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(medmnist, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython_class\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resize:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'orgnamnist3d'"
     ]
    }
   ],
   "source": [
    "from datasets.MedMNIST2D_dataset import MedMNISTDataModule\n",
    "data_module = MedMNISTDataModule('orgnamnist3d', batch_size=32, resize=False, as_rgb=True, size=28, download=True)\n",
    "data_module.setup()\n",
    "train_loader = data_module.train_dataloader()\n",
    "val_loader = data_module.val_dataloader()\n",
    "test_loader = data_module.test_dataloader()\n",
    "\n",
    "for i, (x, y) in enumerate(val_loader):\n",
    "    break\n",
    "\n",
    "imshow(torchvision.utils.make_grid(x))\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(torch.allclose(x[:, 0, :, :], x[:, 1, :, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 19\u001b[0m\n\u001b[1;32m     14\u001b[0m dl \u001b[38;5;241m=\u001b[39m DataLoader(paired_train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# for i, (x, y) in enumerate(dl):\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     break\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (x1,y1), (x2,y2) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dl):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "size=28\n",
    "download=False\n",
    "as_rgb=True\n",
    "info = INFO['tissuemnist']\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[.5], std=[.5])\n",
    "            ])\n",
    "train_dataset = DataClass(split='train', transform=transform, download=download, as_rgb=as_rgb, size=size)\n",
    "from datasets.CnMedMNIST2D_dataset import PairedCnMedMNIST2D\n",
    "paired_train_dataset = PairedCnMedMNIST2D(train_dataset, transform, x2_angle=90, split='train')\n",
    "#dl = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "dl = DataLoader(paired_train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "# for i, (x, y) in enumerate(dl):\n",
    "#     break\n",
    "for i, (x1,y1), (x2,y2) in enumerate(dl):\n",
    "    break\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using latent transformation from generators\n",
      "tensor(47945.7383, grad_fn=<DistBackward0>)\n",
      "tensor(8769.2236, grad_fn=<MseLossBackward0>)\n",
      "tensor(712.6738, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from models.FunctorModel import FunctorModel\n",
    "\n",
    "model_path = '/home/rma55/git-repos/MedMNIST_functorial/tb_logs/pathmnist/functor/test_t_reduction_sum_resnet18_lambdaT_0.001_lambdaW_0.0/version_0/checkpoints/best_model.ckpt'\n",
    "model = FunctorModel.load_from_checkpoint(model_path).cpu()\n",
    "model.eval()\n",
    "W4 = torch.linalg.matrix_power(model.W, 4)\n",
    "print(torch.dist(W4, torch.eye(model.W.shape[0])))\n",
    "print(torch.nn.functional.mse_loss(W4, torch.eye(model.W.shape[0])))\n",
    "eigvals, _ = torch.linalg.eig(model.W)\n",
    "print((eigvals**4-1).abs().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003309850348159671\n",
      "7.364004611968994\n",
      "tensor([1.9825, 0.2944, 0.2589, 0.0579, 3.3937, 0.0621, 0.2704, 2.2239, 2.0300,\n",
      "        1.9432, 0.0526, 0.0687, 0.3013, 2.4234, 0.0456, 0.0959, 0.2492, 1.8608,\n",
      "        0.2099, 0.3236, 2.0094, 0.1008, 0.2693, 0.1019, 0.1247, 1.8884, 0.0926,\n",
      "        0.2365, 2.0521, 0.2889, 0.0618, 1.9934],\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n",
      "47945.73828125\n",
      "tensor([13.7281, 14.2701, 11.0624, 15.2156, 23.4890, 12.5819, 12.3383, 14.9206,\n",
      "        14.0348, 12.8879, 14.5321, 14.3753, 13.5820, 17.5298, 13.2571, 15.6681,\n",
      "        11.0716, 13.0431, 14.4844, 15.6511, 13.9023, 12.3412, 12.3321, 13.1769,\n",
      "        13.4292, 13.5617, 13.3932, 16.1296, 14.2016, 13.3557, 17.5484, 14.0300],\n",
      "       grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "_, latent1 = model(x1)\n",
    "_, latent2 = model(x2)\n",
    "transformed_latents = model.get_transformed_latent(latent1, covariate, covariate)\n",
    "print(torch.nn.functional.mse_loss(latent2, transformed_latents).item())\n",
    "print(torch.dist(latent2, transformed_latents).item())\n",
    "print(torch.norm(latent2 - transformed_latents, dim=1))\n",
    "print(torch.dist(W4, torch.eye(model.W.shape[0])).item())\n",
    "print(torch.norm(torch.nn.functional.linear(latent1, W4) - latent1, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.2408,  6.5897, 21.6617], grad_fn=<LinalgVectorNormBackward0>)\n",
      "0.33476197719573975\n",
      "0.33476197719573975\n"
     ]
    }
   ],
   "source": [
    "img = x1[0]\n",
    "_, img_latent = model(img.unsqueeze(0))\n",
    "\n",
    "# rotate img by 90, 180, 270 degrees\n",
    "rotated_imgs = []\n",
    "for i in range(1, 4):\n",
    "    rotated_imgs.append(TF.rotate(img, i*90))\n",
    "rotated_imgs = torch.stack(rotated_imgs)\n",
    "_, rotated_latents = model(rotated_imgs)\n",
    "covariates = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Repeat img_latent 3 times\n",
    "img_latent_repeated = img_latent.repeat(3, 1)\n",
    "transformed_latents = model.get_transformed_latent(img_latent_repeated, covariates, covariates)\n",
    "print(torch.norm(rotated_latents - transformed_latents, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[133, 125, 129, 125]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.char_tables import Cn_CharTable\n",
    "cn_table = Cn_CharTable(4)\n",
    "\n",
    "cn_table.calculate_irreducible_reps_dimensions(model.W)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
